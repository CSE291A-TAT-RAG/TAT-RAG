# TAT-RAG ğŸš€

A complete, production-ready RAG (Retrieval-Augmented Generation) pipeline with **local and cloud LLM support**, Qdrant vector database, and RAGAS evaluation.

## âœ¨ Key Features

- **ğŸŒ Streamlit Web UI**: Interactive chat interface with PDF source navigation
- **ğŸ”„ Flexible LLM Providers**: Ollama (local) or AWS Bedrock (cloud)
- **ğŸ¯ Retrieve-Only Mode**: Perfect for Mac/CPU-only users - no LLM required!
- **ğŸ“š Document Ingestion**: Support for TXT and PDF files
- **ğŸ“„ Advanced PDF Parsing**: Dual parser support with position tracking
  - **LangChain**: Fast, simple loading for general documents
  - **Fitz (PyMuPDF)**: Advanced parsing with bbox coordinates for source navigation
- **ğŸ” Semantic Search**: BGE-M3 multilingual embeddings (local)
- **ğŸ¤– RAG Pipeline**: Context-aware answer generation
- **ğŸ“Š RAGAS Evaluation**: Comprehensive quality metrics
- **ğŸ³ Docker Ready**: Fully containerized with optional GPU support

## ğŸ—ï¸ Architecture

The project operates in three main pipelines:

**1. Ingestion Pipeline**
```
[Source Docs] -> [ingestion.py] -> [embedding_providers.py] -> [Vector DB]
(.txt, .pdf)    (Chunking)       (Create Embeddings)          (Qdrant)
```

**2. RAG Pipeline**
```
[User Query] -> [retrieval.py] -> [embedding_providers.py] -> [Vector DB]
     |           (Search)         (Create Query Embedding)   (Similarity Search)
     |                                                          |
     +--------------------------------------------> [Retrieved Context]
     |                                                          |
     +--------------------------------------------> [llm_providers.py] -> [LLM]
                                                      (Context + Query)    (Ollama/Bedrock)
                                                                             |
                                                                             V
                                                                      [Final Answer]
```

**3. Evaluation Pipeline**
```
[Evaluation CSV] -> [evaluation.py] -> (Runs RAG Pipeline) -> [RAGAS Metrics]
(question, gt)                                                 (Faithfulness, etc.)
```

## ğŸš€ Quick Start

```bash
# Start all services
docker-compose up -d --build

# Ingest documents for windows
docker-compose exec rag-app python main.py ingest //app/data/sample.txt

# Ingest documents for macOS / Linux
docker-compose exec rag-app python main.py ingest /app/data/sample.txt

# Launch Streamlit Web UI
docker-compose exec rag-app streamlit run app.py --server.port 8501 --server.address 0.0.0.0
# Then open: http://localhost:8501
```

## ğŸ“– Usage Examples

### ğŸŒ Web UI (Streamlit)

The easiest way to use TAT-RAG is through the Streamlit web interface:

```bash
# Make sure your documents are ingested first
docker-compose exec rag-app python main.py ingest /app/data/your_file.pdf --file-type pdf --parser fitz

# Launch Streamlit
docker-compose exec rag-app streamlit run app.py --server.port 8501 --server.address 0.0.0.0

# Open in browser: http://localhost:8501
```

**Features:**
- ğŸ’¬ **Chat Interface**: Ask questions and get answers with context
- ğŸ“„ **Source Display**: View retrieved documents with metadata in sidebar
- ğŸ“ **Position Information**: See exact page number and bounding box coordinates
- ğŸ”— **PDF Navigation**: Click "View in PDF" to jump to the source page
- âš™ï¸ **Smart Retrieval**: Control max sources and similarity threshold
  - Adjust top-K (max results to return)
  - Set similarity threshold (filter low-quality results)

**Screenshot Features:**
- Left panel: Chat history and Q&A
- Right panel: Retrieved sources with scores and metadata
- Bottom: PDF viewer that opens when you click on a source

### CLI Commands

```bash
# Ingest documents
docker-compose exec rag-app python main.py ingest /app/data/docs.txt

# Ingest PDF with default (LangChain) parser
docker-compose exec rag-app python main.py ingest /app/data/paper.pdf --file-type pdf

# Ingest PDF with advanced Fitz parser (recommended for financial reports)
docker-compose exec rag-app python main.py ingest /app/data/financial_report.pdf \
  --file-type pdf \
  --parser fitz


# Evaluate with single question (quick test)
# Linux/macOS
docker-compose exec rag-app python main.py evaluate \
  --question "What is RAG?" \
  --ground-truth "RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with text generation" \
  --output /app/output/report.txt

# Windows Git Bash
export MSYS_NO_PATHCONV=1 && docker-compose exec rag-app python main.py evaluate \
  --question "What is RAG?" \
  --ground-truth "RAG stands for Retrieval-Augmented Generation, a technique that combines information retrieval with text generation" \
  --output /app/output/report.txt


# Evaluate with CSV dataset (batch evaluation)
# Linux/macOS
docker-compose exec rag-app python main.py evaluate \
  --csv-path /app/examples/eval_dataset_example.csv \
  --output /app/output/batch_report.txt

# Windows Git Bash
export MSYS_NO_PATHCONV=1 && docker-compose exec rag-app python main.py evaluate \
  --csv-path /app/examples/eval_dataset_example.csv \
  --output /app/output/batch_report.txt
```

### Preview parser
```bash
# Windows Git Bash
export MSYS_NO_PATHCONV=1
docker-compose exec rag-app python scripts/preview_pdf.py /app/data/a10-networks-inc_2019.pdf

# macOs/Linux
docker-compose exec rag-app python scripts/preview_pdf.py /app/data/a10-networks-inc_2019.pdf

# ä½¿ç”¨ LangChain parser
docker-compose exec rag-app python scripts/preview_pdf.py /app/data/a10-networks-inc_2019.pdf --parser langchain
```

### Export to JSON/JSONL
```bash
# å¯¼å‡ºä¸º JSONLï¼ˆæ¯è¡Œä¸€ä¸ª JSONï¼Œæ–¹ä¾¿å¤„ç†å¤§æ–‡ä»¶ï¼‰
docker-compose exec rag-app python scripts/export_parsed_pdf.py \
  /app/data/a10-networks-inc_2019.pdf \
  --output /app/output/a10_parsed.jsonl

# å¯¼å‡ºä¸º JSONï¼ˆå®Œæ•´ JSON æ•°ç»„ï¼Œæ–¹ä¾¿é˜…è¯»ï¼‰
docker-compose exec rag-app python scripts/export_parsed_pdf.py \
  /app/data/a10-networks-inc_2019.pdf \
  --output /app/output/a10_parsed.json \
  --format json

# ä¸æ˜¾ç¤ºé¢„è§ˆï¼Œåªå¯¼å‡º
docker-compose exec rag-app python scripts/export_parsed_pdf.py \
  /app/data/a10-networks-inc_2019.pdf \
  --output /app/output/a10_parsed.jsonl \
  --no-preview
```

## E2E Sample Test

```bash
python e2e_test.py
```

## Unit Test

```bash
docker-compose exec rag-app pytest
```


## âš™ï¸ Configuration

### ğŸš€ Quick Setup (First Time)

**Step 1: Create your configuration file**
```bash
# Copy the template to create your .env file
cp .env.example .env
```

**Step 2: Choose your LLM provider** (edit `.env`)

**Option A: Local Ollama (Default)**
```bash
# Already set by default in .env, no changes needed!
LLM_PROVIDER=ollama
LLM_MODEL=qwen3:8b
```

**Option B: AWS Bedrock (Claude)**
```bash
# Edit .env and change these lines:
LLM_PROVIDER=bedrock
LLM_MODEL=anthropic.claude-3-sonnet-20240229-v1:0
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_actual_access_key
AWS_SECRET_ACCESS_KEY=your_actual_secret_key
```

**Step 3: Start Docker**
```bash
docker-compose up -d
```

> **Note:** Your `.env` file is git-ignored for security. Never commit AWS credentials!

### Switching Between Providers

Simply edit your `.env` file and change the `LLM_PROVIDER` line, then restart Docker:

```bash
docker-compose down
docker-compose up -d
```

### Available Models

**Ollama Models:**
- `qwen3:8b`
- Any model from [Ollama library](https://ollama.com/library)

**AWS Bedrock Models:**
- `anthropic.claude-3-haiku-20240307-v1:0` (Fastest, Cheapest)

## ğŸ“Š RAGAS Evaluation Metrics

- **Faithfulness**: How grounded the answer is in retrieved context
- **Answer Relevancy**: How relevant the answer is to the question
- **Context Precision**: Quality of retrieved documents ranking
- **Context Recall**: Coverage of ground truth in retrieved context
- **Answer Correctness**: Similarity to ground truth answer

Example evaluation dataset (`examples/eval_dataset_example.csv`):
```csv
question,ground_truth
"What is RAG?","RAG combines information retrieval with text generation"
"What is Qdrant used for?","Qdrant is a vector database for similarity search"
```


## ğŸ³ Docker Services

```yaml
services:
  qdrant:    # Vector database (6333, 6334)
  ollama:    # Local LLM server (11434)
  rag-app:   # Your RAG application
```

### GPU Support

Uncomment in `docker-compose.yml`:
```yaml
ollama:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

Then set: `EMBEDDING_DEVICE=cuda` in `.env`

## ğŸ“ Project Structure

```
TAT-RAG/
â”œâ”€â”€ src/                      # Core application logic
â”‚   â”œâ”€â”€ config.py             # Manages all configurations from .env file
â”‚   â”œâ”€â”€ llm_providers.py      # Interface for different LLMs (Ollama, Bedrock)
â”‚   â”œâ”€â”€ embedding_providers.py# Interface for embedding models (local BGE)
â”‚   â”œâ”€â”€ parsers/              # Document parsing strategies
â”‚   â”‚   â”œâ”€â”€ base.py           # Abstract parser interface
â”‚   â”‚   â”œâ”€â”€ langchain_parser.py  # Simple, fast parser
â”‚   â”‚   â””â”€â”€ fitz_parser.py    # Advanced PDF parser (PyMuPDF)
â”‚   â”œâ”€â”€ ingestion.py          # Handles document reading, chunking, and embedding storage
â”‚   â”œâ”€â”€ retrieval.py          # Performs semantic search and answer generation
â”‚   â””â”€â”€ evaluation.py         # Calculates RAG quality metrics using RAGAS
â”œâ”€â”€ data/                     # (Recommended) Directory for your source documents
â”œâ”€â”€ examples/                 # Example files for testing and evaluation
â”‚   â”œâ”€â”€ eval_dataset_example.csv
â”‚   â””â”€â”€ test_parsers.py       # Compare LangChain vs Fitz parsers
â”œâ”€â”€ output/                   # (Generated) Default directory for evaluation reports
â”œâ”€â”€ scripts/                  # Helper scripts
â”‚   â””â”€â”€ setup_ollama.sh       # Setup script for Linux/Mac
â”œâ”€â”€ main.py                   # Main CLI entry point for all operations (ingest, evaluate)
â”œâ”€â”€ e2e_test.py               # Automated end-to-end test script
â”œâ”€â”€ docker-compose.yml        # Defines and orchestrates all services (Qdrant, Ollama, App)
â”œâ”€â”€ Dockerfile                # Builds the Python application container
â”œâ”€â”€ requirements.txt          # Python package dependencies
â”œâ”€â”€ .env.example              # Template for environment configuration (commit this)
â”œâ”€â”€ .env                      # Your actual configuration (git-ignored, NEVER commit!)
â””â”€â”€ README.md                 # This file
```

## ğŸŒŸ Tech Stack

- **Vector Database**: Qdrant (cosine similarity)
- **LLM**: Ollama (Qwen/Llama/Mistral) or AWS Bedrock (Claude)
- **Embeddings**: BGE-M3 (local)
- **Evaluation**: RAGAS framework
- **Document Loading**: LangChain loaders + PyMuPDF
- **Deployment**: Docker & Docker Compose

## ğŸ“„ PDF Parser Selection Guide

### When to Use Which Parser?

| Parser | Best For | Pros | Cons |
|--------|----------|------|------|
| **langchain** (default) | Simple documents, TXT files, quick testing | âœ… Fast<br>âœ… Simple<br>âœ… Multiple formats | âŒ Basic PDF extraction<br>âŒ Poor paragraph boundaries |
| **fitz** (PyMuPDF) | Financial reports, complex PDFs, production use | âœ… Respects PDF structure<br>âœ… Better text quality<br>âœ… Reading order sorting<br>âœ… Handles encrypted PDFs | âŒ PDF only<br>âŒ Slightly slower |

### Example Usage

```bash
# Test both parsers on your PDF
docker-compose exec rag-app python examples/test_parsers.py /app/data/your_file.pdf

# Use LangChain parser (default)
docker-compose exec rag-app python main.py ingest /app/data/report.pdf --file-type pdf

# Use Fitz parser (recommended for financial documents)
docker-compose exec rag-app python main.py ingest /app/data/report.pdf --file-type pdf --parser fitz
```

### Key Differences

**LangChain Parser:**
- Uses PyPDFLoader internally
- Page-level extraction
- Simple and fast
- Good for basic documents

**Fitz Parser (PyMuPDF):**
- Extracts text blocks in reading order (topâ†’bottom, leftâ†’right)
- Preserves paragraph boundaries
- Better text normalization
- Handles edge cases (encrypted PDFs, complex layouts)
- Ideal for financial reports (10-K, 10-Q, annual reports)

## ğŸ“š Documentation

- [examples/example_usage.py](examples/example_usage.py) - Python API examples
- [.env.example](.env.example) - All configuration options


## ğŸ™ Acknowledgments

- [Ollama](https://ollama.com/) - Local LLM inference
- [Qdrant](https://qdrant.tech/) - Vector database
- [RAGAS](https://github.com/explodinggradients/ragas) - RAG evaluation
- [BGE](https://huggingface.co/BAAI/bge-m3) - Multilingual embeddings
- [LangChain](https://langchain.com/) - Document loaders
